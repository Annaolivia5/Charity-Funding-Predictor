{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df  = application_df.drop(columns= ['EIN', 'NAME'])\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "unique_value_counts = application_df.nunique()\n",
    "unique_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________\n",
      "APPLICATION_TYPE\n",
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T14        3\n",
      "T25        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "_____________________________\n",
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C1370        1\n",
      "C1283        1\n",
      "C1732        1\n",
      "C1580        1\n",
      "C5200        1\n",
      "Name: CLASSIFICATION, Length: 71, dtype: int64\n",
      "_____________________________\n",
      "ASK_AMT\n",
      "5000       25398\n",
      "10478          3\n",
      "15583          3\n",
      "6725           3\n",
      "63981          3\n",
      "           ...  \n",
      "772556         1\n",
      "70103          1\n",
      "27096          1\n",
      "25049          1\n",
      "1138700        1\n",
      "Name: ASK_AMT, Length: 8747, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For  columns w/ more than 10 unique values, \n",
    "# determine the number of data points for each unique value.\n",
    "keys = unique_value_counts.keys()\n",
    "counter = 0\n",
    "\n",
    "for i in unique_value_counts:\n",
    "    if i > 10:\n",
    "        current_col = keys[counter]\n",
    "        print('_____________________________')\n",
    "        print(current_col)\n",
    "        print(application_df[current_col].value_counts())\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3</td>\n",
       "      <td>27037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T4</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T6</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T19</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T8</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T10</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T13</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_type  count\n",
       "0        T3  27037\n",
       "1        T4   1542\n",
       "2        T6   1216\n",
       "3        T5   1173\n",
       "4       T19   1065\n",
       "5        T8    737\n",
       "6        T7    725\n",
       "7       T10    528\n",
       "8        T9    156\n",
       "9       T13     66\n",
       "10      T12     27\n",
       "11       T2     16\n",
       "12      T14      3\n",
       "13      T25      3\n",
       "14      T29      2\n",
       "15      T15      2\n",
       "16      T17      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_type_counts = application_df.APPLICATION_TYPE.value_counts()\n",
    "app_type_counts_df = pd.DataFrame(app_type_counts)\n",
    "app_type_counts_df.reset_index(inplace=True)\n",
    "app_type_counts_df.columns = ['app_type', 'count']\n",
    "app_type_counts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Other      804\n",
       "T8         737\n",
       "T7         725\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = []\n",
    "\n",
    "for i in range(len(app_type_counts_df)):\n",
    "    if (app_type_counts_df.loc[i, 'count'] < 700):\n",
    "        application_types_to_replace.append(app_type_counts_df.loc[i, 'app_type'])\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1000</td>\n",
       "      <td>17326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2000</td>\n",
       "      <td>6074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1200</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C3000</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2100</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>C1370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>C1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>C1732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>C1580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>C5200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  count\n",
       "0           C1000  17326\n",
       "1           C2000   6074\n",
       "2           C1200   4837\n",
       "3           C3000   1918\n",
       "4           C2100   1883\n",
       "..            ...    ...\n",
       "66          C1370      1\n",
       "67          C1283      1\n",
       "68          C1732      1\n",
       "69          C1580      1\n",
       "70          C5200      1\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_counts = application_df.CLASSIFICATION.value_counts()\n",
    "classification_counts_df = pd.DataFrame(classification_counts)\n",
    "classification_counts_df.reset_index(inplace=True)\n",
    "classification_counts_df.columns = ['classification', 'count']\n",
    "classification_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1000</td>\n",
       "      <td>17326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2000</td>\n",
       "      <td>6074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1200</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C3000</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2100</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C7000</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1700</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C4000</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C5000</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C1270</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C2700</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C2800</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C7100</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C1300</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C1280</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C1230</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C1400</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C7200</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C2300</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C1240</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C8000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C7120</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C1500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C6000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C1800</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C1250</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C8200</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C1238</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C1278</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C1237</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C1235</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>C7210</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>C2400</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>C1720</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>C4100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>C1257</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C1600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C2710</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C1260</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>C0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>C3200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>C1246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>C1256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>C1267</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>C1234</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  count\n",
       "0           C1000  17326\n",
       "1           C2000   6074\n",
       "2           C1200   4837\n",
       "3           C3000   1918\n",
       "4           C2100   1883\n",
       "5           C7000    777\n",
       "6           C1700    287\n",
       "7           C4000    194\n",
       "8           C5000    116\n",
       "9           C1270    114\n",
       "10          C2700    104\n",
       "11          C2800     95\n",
       "12          C7100     75\n",
       "13          C1300     58\n",
       "14          C1280     50\n",
       "15          C1230     36\n",
       "16          C1400     34\n",
       "17          C7200     32\n",
       "18          C2300     32\n",
       "19          C1240     30\n",
       "20          C8000     20\n",
       "21          C7120     18\n",
       "22          C1500     16\n",
       "23          C6000     15\n",
       "24          C1800     15\n",
       "25          C1250     14\n",
       "26          C8200     11\n",
       "27          C1238     10\n",
       "28          C1278     10\n",
       "29          C1237      9\n",
       "30          C1235      9\n",
       "31          C7210      7\n",
       "32          C2400      6\n",
       "33          C1720      6\n",
       "34          C4100      6\n",
       "35          C1257      5\n",
       "36          C1600      5\n",
       "37          C2710      3\n",
       "38          C1260      3\n",
       "39             C0      3\n",
       "40          C3200      2\n",
       "41          C1246      2\n",
       "42          C1256      2\n",
       "43          C1267      2\n",
       "44          C1234      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "classification_counts_df[classification_counts_df['count']>1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = []\n",
    "\n",
    "for i in range(len(classification_counts_df)):\n",
    "    if (classification_counts_df.loc[i, 'count'] <= 700):\n",
    "        classifications_to_replace.append(classification_counts_df.loc[i, 'classification'])\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       1   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    1                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "4                         0                    1                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "34298                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "1                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "4                        0                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "34298                    0                    0                    0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                      0                       0                         0   \n",
       "1                      1                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       1                         0   \n",
       "4                      0                       0                         1   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                  0                       0                         0   \n",
       "34295                  0                       0                         0   \n",
       "34296                  0                       0                         0   \n",
       "34297                  0                       0                         0   \n",
       "34298                  0                       0                         0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                       0                 0                       0   \n",
       "1                       0                 0                       0   \n",
       "2                       0                 0                       0   \n",
       "3                       0                 0                       0   \n",
       "4                       0                 0                       0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                   0                 0                       0   \n",
       "34295                   0                 0                       0   \n",
       "34296                   0                 0                       0   \n",
       "34297                   0                 0                       0   \n",
       "34298                   0                 1                       0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                    0                  0                         1   \n",
       "1                    0                  0                         1   \n",
       "2                    0                  0                         1   \n",
       "3                    0                  0                         1   \n",
       "4                    0                  0                         1   \n",
       "...                ...                ...                       ...   \n",
       "34294                0                  0                         1   \n",
       "34295                0                  0                         1   \n",
       "34296                0                  0                         1   \n",
       "34297                0                  0                         1   \n",
       "34298                0                  0                         1   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "...                         ...  \n",
       "34294                         0  \n",
       "34295                         0  \n",
       "34296                         0  \n",
       "34297                         0  \n",
       "34298                         0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummies_df = pd.get_dummies(application_df)\n",
    "dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = dummies_df['IS_SUCCESSFUL'].values\n",
    "X = dummies_df.drop('IS_SUCCESSFUL', axis=1).values\n",
    "\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above, values were added to the 'other' bin for Classication and Application Type columns.\n",
    "##### First Attempt: Number of neurons in each layer increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                924       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 22        \n",
      "=================================================================\n",
      "Total params: 2,838\n",
      "Trainable params: 2,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "number_input_features = len(X_train[0])\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features, activation=\"relu\", input_dim=number_input_features)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\")) \n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5754 - accuracy: 0.7191 - loss: 0.5759 - accuracy: 0.71\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5557 - accuracy: 0.7291\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5534 - accuracy: 0.7303\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5510 - accuracy: 0.7310\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5502 - accuracy: 0.7318\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5485 - accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5473 - accuracy: 0.7329s - loss: 0.5482 - accuracy: 0.\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5470 - accuracy: 0.7325\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5463 - accuracy: 0.7322\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5455 - accuracy: 0.7347\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5453 - accuracy: 0.7348\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5452 - accuracy: 0.7341\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5448 - accuracy: 0.7347\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.5449 - accuracy: 0.7350\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 0.5442 - accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.5438 - accuracy: 0.7338\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5438 - accuracy: 0.7353\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5434 - accuracy: 0.7346\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5435 - accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5432 - accuracy: 0.7355\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 4s 166us/sample - loss: 0.5432 - accuracy: 0.7352\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5427 - accuracy: 0.7340\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5426 - accuracy: 0.7353\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5427 - accuracy: 0.7356\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5420 - accuracy: 0.7374\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5421 - accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5419 - accuracy: 0.7378\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5415 - accuracy: 0.7364\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5418 - accuracy: 0.7357\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5413 - accuracy: 0.7368\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 4s 156us/sample - loss: 0.5410 - accuracy: 0.7381\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5408 - accuracy: 0.7374\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5408 - accuracy: 0.7375\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 0.5408 - accuracy: 0.7371\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5407 - accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5404 - accuracy: 0.7365\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.5401 - accuracy: 0.7379\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 4s 173us/sample - loss: 0.5401 - accuracy: 0.7381\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 5s 190us/sample - loss: 0.5404 - accuracy: 0.7378\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5400 - accuracy: 0.7379\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 5s 180us/sample - loss: 0.5399 - accuracy: 0.7382\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 5s 189us/sample - loss: 0.5395 - accuracy: 0.7372\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 5s 182us/sample - loss: 0.5390 - accuracy: 0.7376\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 6s 221us/sample - loss: 0.5394 - accuracy: 0.7389\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 4s 168us/sample - loss: 0.5393 - accuracy: 0.7387\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 6s 216us/sample - loss: 0.5395 - accuracy: 0.7378\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5388 - accuracy: 0.7386 -\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5391 - accuracy: 0.7384\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.5389 - accuracy: 0.7385\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5390 - accuracy: 0.7383\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5386 - accuracy: 0.7388\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.5386 - accuracy: 0.7382\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5387 - accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5388 - accuracy: 0.7385\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 4s 141us/sample - loss: 0.5385 - accuracy: 0.7387\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5382 - accuracy: 0.7394\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5383 - accuracy: 0.7379\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5380 - accuracy: 0.7396\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5377 - accuracy: 0.7400\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5382 - accuracy: 0.7390\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 4s 136us/sample - loss: 0.5377 - accuracy: 0.7396\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5379 - accuracy: 0.7388\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 4s 141us/sample - loss: 0.5377 - accuracy: 0.7396\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5376 - accuracy: 0.7392\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5379 - accuracy: 0.7397\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.5372 - accuracy: 0.7402\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5376 - accuracy: 0.7396\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 4s 141us/sample - loss: 0.5376 - accuracy: 0.7393\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5374 - accuracy: 0.7399\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.5373 - accuracy: 0.7393\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 4s 145us/sample - loss: 0.5372 - accuracy: 0.7385\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5368 - accuracy: 0.7398\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.5374 - accuracy: 0.7402\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 4s 136us/sample - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 4s 141us/sample - loss: 0.5367 - accuracy: 0.7408\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5367 - accuracy: 0.7404\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.5370 - accuracy: 0.7397\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 4s 136us/sample - loss: 0.5368 - accuracy: 0.7403\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5367 - accuracy: 0.7395\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 4s 146us/sample - loss: 0.5370 - accuracy: 0.7399\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5367 - accuracy: 0.7403\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.5363 - accuracy: 0.7395\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5361 - accuracy: 0.7397\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.5369 - accuracy: 0.7407\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.5361 - accuracy: 0.7403 - loss: 0.5368 - accuracy\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5359 - accuracy: 0.7404\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5362 - accuracy: 0.7395 - loss: 0.535\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5364 - accuracy: 0.7402\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 0.5360 - accuracy: 0.7404\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5359 - accuracy: 0.7405\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.5361 - accuracy: 0.7395\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 0.5362 - accuracy: 0.7400\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 4s 150us/sample - loss: 0.5358 - accuracy: 0.7406\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5361 - accuracy: 0.7399\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5358 - accuracy: 0.7405\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.5356 - accuracy: 0.7396\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5352 - accuracy: 0.7400\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.74 - 4s 140us/sample - loss: 0.5354 - accuracy: 0.7406\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 5s 183us/sample - loss: 0.5355 - accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5563 - accuracy: 0.7238\n",
      "Loss: 0.5565977676060735, Accuracy: 0.7238484025001526\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second Attempt: Another layer added, and more nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 21)                924       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                308       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 3,139\n",
      "Trainable params: 3,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "number_input_features = len(X_train[0])\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features, activation=\"relu\", input_dim=number_input_features)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\")) \n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.5763 - accuracy: 0.7167\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5544 - accuracy: 0.7300\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5508 - accuracy: 0.7311\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5492 - accuracy: 0.7337\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5482 - accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.5469 - accuracy: 0.7334\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.5468 - accuracy: 0.7347\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.5459 - accuracy: 0.7331\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5456 - accuracy: 0.7337\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5452 - accuracy: 0.7350\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.5446 - accuracy: 0.7343\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5443 - accuracy: 0.7355\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5440 - accuracy: 0.7358\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5436 - accuracy: 0.7348\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5434 - accuracy: 0.7364\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5434 - accuracy: 0.7358\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5427 - accuracy: 0.7362\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5423 - accuracy: 0.7365\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.5425 - accuracy: 0.7359 -\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.5418 - accuracy: 0.7378\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5417 - accuracy: 0.7367\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5419 - accuracy: 0.7364\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5415 - accuracy: 0.7363\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5412 - accuracy: 0.7376\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.5408 - accuracy: 0.7372\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5407 - accuracy: 0.7372\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5406 - accuracy: 0.7365\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5403 - accuracy: 0.7385\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5400 - accuracy: 0.7382\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.5405 - accuracy: 0.7376\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5397 - accuracy: 0.7379\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5396 - accuracy: 0.7385\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5397 - accuracy: 0.7382\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5392 - accuracy: 0.7377\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5392 - accuracy: 0.7381\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5394 - accuracy: 0.7374\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5391 - accuracy: 0.7387\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5391 - accuracy: 0.7383\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5388 - accuracy: 0.7381\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5390 - accuracy: 0.7387\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5384 - accuracy: 0.7388\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5388 - accuracy: 0.7389\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5386 - accuracy: 0.7387\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5377 - accuracy: 0.7393\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5387 - accuracy: 0.7385\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.5380 - accuracy: 0.7387\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.5379 - accuracy: 0.7385\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 4s 174us/sample - loss: 0.5379 - accuracy: 0.7385\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 5s 184us/sample - loss: 0.5380 - accuracy: 0.7385\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 0.5370 - accuracy: 0.7392\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 4s 168us/sample - loss: 0.5382 - accuracy: 0.7385\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5381 - accuracy: 0.7386\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 5s 176us/sample - loss: 0.5370 - accuracy: 0.7380\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 0.5373 - accuracy: 0.7385\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5369 - accuracy: 0.7387\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5370 - accuracy: 0.7391\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 4s 164us/sample - loss: 0.5368 - accuracy: 0.7394\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5369 - accuracy: 0.7392\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 4s 166us/sample - loss: 0.5369 - accuracy: 0.7395\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 0.5371 - accuracy: 0.7387\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 5s 192us/sample - loss: 0.5366 - accuracy: 0.7394\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 4s 175us/sample - loss: 0.5363 - accuracy: 0.7402\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5364 - accuracy: 0.7390\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 4s 175us/sample - loss: 0.5366 - accuracy: 0.7395\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 5s 187us/sample - loss: 0.5365 - accuracy: 0.7392\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5365 - accuracy: 0.7392\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5363 - accuracy: 0.7399\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5364 - accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5362 - accuracy: 0.7411\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5362 - accuracy: 0.7398\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 4s 173us/sample - loss: 0.5363 - accuracy: 0.7397 - loss:\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5357 - accuracy: 0.7400\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5358 - accuracy: 0.7402\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5358 - accuracy: 0.7387\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5359 - accuracy: 0.7402\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 4s 156us/sample - loss: 0.5355 - accuracy: 0.7397\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 4s 162us/sample - loss: 0.5357 - accuracy: 0.7395\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 4s 163us/sample - loss: 0.5355 - accuracy: 0.7402\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.5352 - accuracy: 0.7400\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 4s 172us/sample - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5353 - accuracy: 0.7407\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.5354 - accuracy: 0.7402\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 4s 162us/sample - loss: 0.5352 - accuracy: 0.7402\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5351 - accuracy: 0.7403\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 4s 163us/sample - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 0.5355 - accuracy: 0.7399\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.5354 - accuracy: 0.7401\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5350 - accuracy: 0.7411\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5356 - accuracy: 0.7395\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 5s 185us/sample - loss: 0.5355 - accuracy: 0.7412\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 4s 174us/sample - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 4s 156us/sample - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 4s 150us/sample - loss: 0.5350 - accuracy: 0.7405\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 4s 172us/sample - loss: 0.5350 - accuracy: 0.7402\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 4s 163us/sample - loss: 0.5350 - accuracy: 0.7409\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5349 - accuracy: 0.7405\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 5s 181us/sample - loss: 0.5349 - accuracy: 0.7406\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5534 - accuracy: 0.7257\n",
      "Loss: 0.5544330729687527, Accuracy: 0.7257142663002014\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third Attempt: Rows with outliers in Ask Ammount removed\n",
    "##### The number of layers and neurons is the same as the last attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Bound: 887.0\n",
      "Upper Bound: 11855.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26093, 44)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find outliers for ASK_AMT \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ask_ammounts = dummies_df['ASK_AMT']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('ASK_AMT')\n",
    "ax1.boxplot(ask_ammounts)\n",
    "plt.show()\n",
    "\n",
    "quartiles = np.quantile(ask_ammounts,[.25,.75])\n",
    "iqr = quartiles[1]-quartiles[0]\n",
    "lower_bound = quartiles[0]-(1.5*iqr)\n",
    "upper_bound = quartiles[1]+(1.5*iqr)\n",
    "print(f'Lower Bound: {lower_bound}')\n",
    "print(f'Upper Bound: {upper_bound}')\n",
    "\n",
    "dummies_df.drop(dummies_df[dummies_df['ASK_AMT'] < lower_bound ].index, inplace = True)\n",
    "dummies_df.drop(dummies_df[dummies_df['ASK_AMT'] > upper_bound ].index, inplace = True)\n",
    "dummies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y2 = dummies_df['IS_SUCCESSFUL'].values\n",
    "X2 = dummies_df.drop('IS_SUCCESSFUL', axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=78) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler2 = scaler2.fit(X_train2)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 21)                924       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 14)                308       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 3,139\n",
      "Trainable params: 3,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "number_input_features = len(X_train2[0])\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features, activation=\"relu\", input_dim=number_input_features)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\")) \n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19569 samples\n",
      "Epoch 1/100\n",
      "19569/19569 [==============================] - 3s 152us/sample - loss: 0.5714 - accuracy: 0.7278\n",
      "Epoch 2/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5347 - accuracy: 0.7454\n",
      "Epoch 3/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5316 - accuracy: 0.7478\n",
      "Epoch 4/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5300 - accuracy: 0.7482\n",
      "Epoch 5/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5292 - accuracy: 0.7490\n",
      "Epoch 6/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5283 - accuracy: 0.7480s - l\n",
      "Epoch 7/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5273 - accuracy: 0.7495\n",
      "Epoch 8/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5267 - accuracy: 0.7498\n",
      "Epoch 9/100\n",
      "19569/19569 [==============================] - 2s 86us/sample - loss: 0.5264 - accuracy: 0.7502\n",
      "Epoch 10/100\n",
      "19569/19569 [==============================] - 2s 90us/sample - loss: 0.5252 - accuracy: 0.7503\n",
      "Epoch 11/100\n",
      "19569/19569 [==============================] - 2s 118us/sample - loss: 0.5254 - accuracy: 0.7501\n",
      "Epoch 12/100\n",
      "19569/19569 [==============================] - 2s 102us/sample - loss: 0.5247 - accuracy: 0.7521\n",
      "Epoch 13/100\n",
      "19569/19569 [==============================] - 2s 99us/sample - loss: 0.5245 - accuracy: 0.7506\n",
      "Epoch 14/100\n",
      "19569/19569 [==============================] - 2s 102us/sample - loss: 0.5243 - accuracy: 0.7509\n",
      "Epoch 15/100\n",
      "19569/19569 [==============================] - 2s 101us/sample - loss: 0.5242 - accuracy: 0.7507\n",
      "Epoch 16/100\n",
      "19569/19569 [==============================] - 2s 99us/sample - loss: 0.5236 - accuracy: 0.7512\n",
      "Epoch 17/100\n",
      "19569/19569 [==============================] - 2s 97us/sample - loss: 0.5234 - accuracy: 0.7519\n",
      "Epoch 18/100\n",
      "19569/19569 [==============================] - 2s 96us/sample - loss: 0.5235 - accuracy: 0.7516\n",
      "Epoch 19/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5229 - accuracy: 0.7512\n",
      "Epoch 20/100\n",
      "19569/19569 [==============================] - 2s 87us/sample - loss: 0.5225 - accuracy: 0.7529\n",
      "Epoch 21/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5225 - accuracy: 0.7510\n",
      "Epoch 22/100\n",
      "19569/19569 [==============================] - 2s 86us/sample - loss: 0.5224 - accuracy: 0.7517\n",
      "Epoch 23/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5217 - accuracy: 0.7526\n",
      "Epoch 24/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5224 - accuracy: 0.7520\n",
      "Epoch 25/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5221 - accuracy: 0.7525\n",
      "Epoch 26/100\n",
      "19569/19569 [==============================] - 2s 90us/sample - loss: 0.5218 - accuracy: 0.7514\n",
      "Epoch 27/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5217 - accuracy: 0.7523\n",
      "Epoch 28/100\n",
      "19569/19569 [==============================] - 2s 84us/sample - loss: 0.5212 - accuracy: 0.7534\n",
      "Epoch 29/100\n",
      "19569/19569 [==============================] - 2s 87us/sample - loss: 0.5210 - accuracy: 0.7524\n",
      "Epoch 30/100\n",
      "19569/19569 [==============================] - 2s 87us/sample - loss: 0.5210 - accuracy: 0.7529\n",
      "Epoch 31/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5211 - accuracy: 0.7522\n",
      "Epoch 32/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5207 - accuracy: 0.7532\n",
      "Epoch 33/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5202 - accuracy: 0.7528\n",
      "Epoch 34/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5201 - accuracy: 0.7527\n",
      "Epoch 35/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5205 - accuracy: 0.7535\n",
      "Epoch 36/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5201 - accuracy: 0.7535\n",
      "Epoch 37/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5194 - accuracy: 0.7537\n",
      "Epoch 38/100\n",
      "19569/19569 [==============================] - 2s 109us/sample - loss: 0.5198 - accuracy: 0.7529 - loss: 0.516\n",
      "Epoch 39/100\n",
      "19569/19569 [==============================] - 2s 86us/sample - loss: 0.5197 - accuracy: 0.7527\n",
      "Epoch 40/100\n",
      "19569/19569 [==============================] - 2s 106us/sample - loss: 0.5195 - accuracy: 0.7536\n",
      "Epoch 41/100\n",
      "19569/19569 [==============================] - 3s 159us/sample - loss: 0.5195 - accuracy: 0.7540\n",
      "Epoch 42/100\n",
      "19569/19569 [==============================] - 3s 140us/sample - loss: 0.5192 - accuracy: 0.7533\n",
      "Epoch 43/100\n",
      "19569/19569 [==============================] - 3s 148us/sample - loss: 0.5195 - accuracy: 0.7535\n",
      "Epoch 44/100\n",
      "19569/19569 [==============================] - 3s 147us/sample - loss: 0.5198 - accuracy: 0.7535\n",
      "Epoch 45/100\n",
      "19569/19569 [==============================] - 4s 191us/sample - loss: 0.5191 - accuracy: 0.7537\n",
      "Epoch 46/100\n",
      "19569/19569 [==============================] - 4s 185us/sample - loss: 0.5192 - accuracy: 0.7538\n",
      "Epoch 47/100\n",
      "19569/19569 [==============================] - 3s 167us/sample - loss: 0.5188 - accuracy: 0.7539\n",
      "Epoch 48/100\n",
      "19569/19569 [==============================] - 3s 159us/sample - loss: 0.5182 - accuracy: 0.7542\n",
      "Epoch 49/100\n",
      "19569/19569 [==============================] - 3s 151us/sample - loss: 0.5188 - accuracy: 0.7536\n",
      "Epoch 50/100\n",
      "19569/19569 [==============================] - 3s 151us/sample - loss: 0.5185 - accuracy: 0.7533\n",
      "Epoch 51/100\n",
      "19569/19569 [==============================] - 3s 164us/sample - loss: 0.5183 - accuracy: 0.7533\n",
      "Epoch 52/100\n",
      "19569/19569 [==============================] - 3s 144us/sample - loss: 0.5182 - accuracy: 0.7534\n",
      "Epoch 53/100\n",
      "19569/19569 [==============================] - 3s 149us/sample - loss: 0.5181 - accuracy: 0.7537\n",
      "Epoch 54/100\n",
      "19569/19569 [==============================] - 3s 154us/sample - loss: 0.5184 - accuracy: 0.7537\n",
      "Epoch 55/100\n",
      "19569/19569 [==============================] - 3s 158us/sample - loss: 0.5179 - accuracy: 0.7545\n",
      "Epoch 56/100\n",
      "19569/19569 [==============================] - 3s 146us/sample - loss: 0.5177 - accuracy: 0.7545\n",
      "Epoch 57/100\n",
      "19569/19569 [==============================] - 3s 146us/sample - loss: 0.5181 - accuracy: 0.7535\n",
      "Epoch 58/100\n",
      "19569/19569 [==============================] - 3s 149us/sample - loss: 0.5178 - accuracy: 0.7539\n",
      "Epoch 59/100\n",
      "19569/19569 [==============================] - 3s 147us/sample - loss: 0.5178 - accuracy: 0.7543\n",
      "Epoch 60/100\n",
      "19569/19569 [==============================] - 3s 150us/sample - loss: 0.5173 - accuracy: 0.7538\n",
      "Epoch 61/100\n",
      "19569/19569 [==============================] - 3s 156us/sample - loss: 0.5176 - accuracy: 0.7543\n",
      "Epoch 62/100\n",
      "19569/19569 [==============================] - 3s 146us/sample - loss: 0.5172 - accuracy: 0.7545\n",
      "Epoch 63/100\n",
      "19569/19569 [==============================] - 3s 141us/sample - loss: 0.5175 - accuracy: 0.7536\n",
      "Epoch 64/100\n",
      "19569/19569 [==============================] - 3s 157us/sample - loss: 0.5169 - accuracy: 0.7535\n",
      "Epoch 65/100\n",
      "19569/19569 [==============================] - 3s 148us/sample - loss: 0.5172 - accuracy: 0.7542\n",
      "Epoch 66/100\n",
      "19569/19569 [==============================] - 3s 146us/sample - loss: 0.5175 - accuracy: 0.7538\n",
      "Epoch 67/100\n",
      "19569/19569 [==============================] - 3s 156us/sample - loss: 0.5171 - accuracy: 0.7545\n",
      "Epoch 68/100\n",
      "19569/19569 [==============================] - 3s 144us/sample - loss: 0.5172 - accuracy: 0.7540\n",
      "Epoch 69/100\n",
      "19569/19569 [==============================] - 3s 158us/sample - loss: 0.5172 - accuracy: 0.7543\n",
      "Epoch 70/100\n",
      "19569/19569 [==============================] - 3s 145us/sample - loss: 0.5168 - accuracy: 0.7542\n",
      "Epoch 71/100\n",
      "19569/19569 [==============================] - 3s 149us/sample - loss: 0.5166 - accuracy: 0.7536\n",
      "Epoch 72/100\n",
      "19569/19569 [==============================] - 3s 148us/sample - loss: 0.5167 - accuracy: 0.7538\n",
      "Epoch 73/100\n",
      "19569/19569 [==============================] - 3s 159us/sample - loss: 0.5167 - accuracy: 0.7538\n",
      "Epoch 74/100\n",
      "19569/19569 [==============================] - 3s 151us/sample - loss: 0.5167 - accuracy: 0.7547\n",
      "Epoch 75/100\n",
      "19569/19569 [==============================] - 3s 142us/sample - loss: 0.5164 - accuracy: 0.7550\n",
      "Epoch 76/100\n",
      "19569/19569 [==============================] - 3s 143us/sample - loss: 0.5165 - accuracy: 0.7543\n",
      "Epoch 77/100\n",
      "19569/19569 [==============================] - 3s 148us/sample - loss: 0.5164 - accuracy: 0.7541\n",
      "Epoch 78/100\n",
      "19569/19569 [==============================] - 3s 150us/sample - loss: 0.5168 - accuracy: 0.7538\n",
      "Epoch 79/100\n",
      "19569/19569 [==============================] - 4s 185us/sample - loss: 0.5159 - accuracy: 0.7547\n",
      "Epoch 80/100\n",
      "19569/19569 [==============================] - 3s 142us/sample - loss: 0.5159 - accuracy: 0.7545\n",
      "Epoch 81/100\n",
      "19569/19569 [==============================] - 2s 112us/sample - loss: 0.5165 - accuracy: 0.7548\n",
      "Epoch 82/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5158 - accuracy: 0.7554\n",
      "Epoch 83/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5161 - accuracy: 0.7545\n",
      "Epoch 84/100\n",
      "19569/19569 [==============================] - 2s 122us/sample - loss: 0.5162 - accuracy: 0.7545\n",
      "Epoch 85/100\n",
      "19569/19569 [==============================] - 2s 93us/sample - loss: 0.5157 - accuracy: 0.7545\n",
      "Epoch 86/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5158 - accuracy: 0.7547\n",
      "Epoch 87/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5160 - accuracy: 0.7549\n",
      "Epoch 88/100\n",
      "19569/19569 [==============================] - 2s 81us/sample - loss: 0.5157 - accuracy: 0.7543\n",
      "Epoch 89/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5159 - accuracy: 0.7549\n",
      "Epoch 90/100\n",
      "19569/19569 [==============================] - 2s 104us/sample - loss: 0.5158 - accuracy: 0.7555\n",
      "Epoch 91/100\n",
      "19569/19569 [==============================] - 2s 118us/sample - loss: 0.5159 - accuracy: 0.7540 - loss: 0.512\n",
      "Epoch 92/100\n",
      "19569/19569 [==============================] - 2s 112us/sample - loss: 0.5159 - accuracy: 0.7549\n",
      "Epoch 93/100\n",
      "19569/19569 [==============================] - 2s 105us/sample - loss: 0.5154 - accuracy: 0.7549\n",
      "Epoch 94/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5154 - accuracy: 0.7549\n",
      "Epoch 95/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5156 - accuracy: 0.7551\n",
      "Epoch 96/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5151 - accuracy: 0.7548\n",
      "Epoch 97/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5154 - accuracy: 0.7556\n",
      "Epoch 98/100\n",
      "19569/19569 [==============================] - 2s 84us/sample - loss: 0.5152 - accuracy: 0.7545\n",
      "Epoch 99/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5153 - accuracy: 0.7552\n",
      "Epoch 100/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5154 - accuracy: 0.7551\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled2, y_train2, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6524/1 - 0s - loss: 0.5446 - accuracy: 0.7498\n",
      "Loss: 0.5405569815109436, Accuracy: 0.7498466968536377\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled2,y_test2,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourth Attempt: Removing the SPECIAL_CONSIDERATIONS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34293</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26093 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1     5000              1                       1   \n",
       "2           1     5000              0                       0   \n",
       "3           1     6692              1                       0   \n",
       "5           1     5000              1                       0   \n",
       "9           1     5000              0                       0   \n",
       "...       ...      ...            ...                     ...   \n",
       "34293       1     5000              1                       0   \n",
       "34294       1     5000              0                       0   \n",
       "34295       1     5000              0                       0   \n",
       "34296       1     5000              0                       0   \n",
       "34297       1     5000              1                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "5                         0                    1                    0   \n",
       "9                         0                    0                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34293                     0                    1                    0   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "5                        0                    0                    0  ...   \n",
       "9                        1                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34293                    0                    0                    0  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "\n",
       "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0                       0             1                  0   \n",
       "2                       0             1                  0   \n",
       "3                       1             0                  0   \n",
       "5                       1             1                  0   \n",
       "9                       0             1                  0   \n",
       "...                   ...           ...                ...   \n",
       "34293                   0             1                  0   \n",
       "34294                   0             1                  0   \n",
       "34295                   0             1                  0   \n",
       "34296                   0             1                  0   \n",
       "34297                   0             1                  0   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                           0                         0                   0   \n",
       "2                           0                         0                   0   \n",
       "3                           1                         0                   0   \n",
       "5                           0                         0                   0   \n",
       "9                           0                         0                   0   \n",
       "...                       ...                       ...                 ...   \n",
       "34293                       0                         0                   0   \n",
       "34294                       0                         0                   0   \n",
       "34295                       0                         0                   0   \n",
       "34296                       0                         0                   0   \n",
       "34297                       0                         0                   0   \n",
       "\n",
       "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                     0                       0                0   \n",
       "2                     0                       0                0   \n",
       "3                     0                       0                0   \n",
       "5                     0                       0                0   \n",
       "9                     0                       0                0   \n",
       "...                 ...                     ...              ...   \n",
       "34293                 0                       0                0   \n",
       "34294                 0                       0                0   \n",
       "34295                 0                       0                0   \n",
       "34296                 0                       0                0   \n",
       "34297                 0                       0                0   \n",
       "\n",
       "       INCOME_AMT_5M-10M  \n",
       "0                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "5                      0  \n",
       "9                      0  \n",
       "...                  ...  \n",
       "34293                  0  \n",
       "34294                  0  \n",
       "34295                  0  \n",
       "34296                  0  \n",
       "34297                  0  \n",
       "\n",
       "[26093 rows x 42 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the special considerations column.\n",
    "dummies_df  = dummies_df.drop(columns= ['SPECIAL_CONSIDERATIONS_N', 'SPECIAL_CONSIDERATIONS_Y'])\n",
    "dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y2 = dummies_df['IS_SUCCESSFUL'].values\n",
    "X2 = dummies_df.drop('IS_SUCCESSFUL', axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=78) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler2 = scaler2.fit(X_train2)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 41)                1722      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                840       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 13)                273       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,849\n",
      "Trainable params: 2,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "number_input_features = len(X_train2[0])\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features, activation=\"relu\", input_dim=number_input_features)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=number_input_features/3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\")) \n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs.\n",
    "checkpoint_filepath = 'saved_weights_5_epochs/optimization/weights_{epoch}_{accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath, \n",
    "    monitor='accuracy', \n",
    "    save_weights_only=True, \n",
    "    mode='auto', \n",
    "    period=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19569 samples\n",
      "Epoch 1/100\n",
      "19569/19569 [==============================] - 3s 158us/sample - loss: 0.5646 - accuracy: 0.7306\n",
      "Epoch 2/100\n",
      "19569/19569 [==============================] - 2s 103us/sample - loss: 0.5364 - accuracy: 0.7430\n",
      "Epoch 3/100\n",
      "19569/19569 [==============================] - 3s 141us/sample - loss: 0.5323 - accuracy: 0.7467\n",
      "Epoch 4/100\n",
      "19569/19569 [==============================] - 3s 140us/sample - loss: 0.5295 - accuracy: 0.7479\n",
      "Epoch 5/100\n",
      "19569/19569 [==============================] - 3s 170us/sample - loss: 0.5292 - accuracy: 0.7472\n",
      "Epoch 6/100\n",
      "19569/19569 [==============================] - 2s 121us/sample - loss: 0.5285 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "19569/19569 [==============================] - 2s 84us/sample - loss: 0.5280 - accuracy: 0.7470\n",
      "Epoch 8/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5270 - accuracy: 0.7498\n",
      "Epoch 9/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5261 - accuracy: 0.7510\n",
      "Epoch 10/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5266 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "19569/19569 [==============================] - 3s 139us/sample - loss: 0.5259 - accuracy: 0.7504 - loss: 0.5253 - accuracy\n",
      "Epoch 12/100\n",
      "19569/19569 [==============================] - 3s 132us/sample - loss: 0.5257 - accuracy: 0.7523\n",
      "Epoch 13/100\n",
      "19569/19569 [==============================] - 2s 114us/sample - loss: 0.5247 - accuracy: 0.7510\n",
      "Epoch 14/100\n",
      "19569/19569 [==============================] - 2s 115us/sample - loss: 0.5250 - accuracy: 0.7511\n",
      "Epoch 15/100\n",
      "19569/19569 [==============================] - 3s 145us/sample - loss: 0.5246 - accuracy: 0.7503\n",
      "Epoch 16/100\n",
      "19569/19569 [==============================] - 2s 97us/sample - loss: 0.5243 - accuracy: 0.7508\n",
      "Epoch 17/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5238 - accuracy: 0.7497\n",
      "Epoch 18/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5234 - accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "19569/19569 [==============================] - 2s 80us/sample - loss: 0.5236 - accuracy: 0.7514\n",
      "Epoch 20/100\n",
      "19569/19569 [==============================] - 2s 81us/sample - loss: 0.5231 - accuracy: 0.7518\n",
      "Epoch 21/100\n",
      "19569/19569 [==============================] - 2s 84us/sample - loss: 0.5230 - accuracy: 0.7511\n",
      "Epoch 22/100\n",
      "19569/19569 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.75 - 2s 86us/sample - loss: 0.5228 - accuracy: 0.7520\n",
      "Epoch 23/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5225 - accuracy: 0.7509\n",
      "Epoch 24/100\n",
      "19569/19569 [==============================] - 2s 87us/sample - loss: 0.5222 - accuracy: 0.7509\n",
      "Epoch 25/100\n",
      "19569/19569 [==============================] - 2s 92us/sample - loss: 0.5223 - accuracy: 0.7516\n",
      "Epoch 26/100\n",
      "19569/19569 [==============================] - 2s 97us/sample - loss: 0.5220 - accuracy: 0.7519\n",
      "Epoch 27/100\n",
      "19569/19569 [==============================] - 2s 84us/sample - loss: 0.5220 - accuracy: 0.7523\n",
      "Epoch 28/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5216 - accuracy: 0.7522\n",
      "Epoch 29/100\n",
      "19569/19569 [==============================] - 2s 92us/sample - loss: 0.5216 - accuracy: 0.7516\n",
      "Epoch 30/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5216 - accuracy: 0.7515\n",
      "Epoch 31/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5210 - accuracy: 0.7518\n",
      "Epoch 32/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5207 - accuracy: 0.7529\n",
      "Epoch 33/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5208 - accuracy: 0.7533\n",
      "Epoch 34/100\n",
      "19569/19569 [==============================] - 2s 97us/sample - loss: 0.5206 - accuracy: 0.7511\n",
      "Epoch 35/100\n",
      "19569/19569 [==============================] - 2s 96us/sample - loss: 0.5203 - accuracy: 0.7532\n",
      "Epoch 36/100\n",
      "19569/19569 [==============================] - 2s 103us/sample - loss: 0.5205 - accuracy: 0.7526\n",
      "Epoch 37/100\n",
      "19569/19569 [==============================] - 2s 95us/sample - loss: 0.5200 - accuracy: 0.7538\n",
      "Epoch 38/100\n",
      "19569/19569 [==============================] - 2s 94us/sample - loss: 0.5200 - accuracy: 0.7522\n",
      "Epoch 39/100\n",
      "19569/19569 [==============================] - 2s 99us/sample - loss: 0.5206 - accuracy: 0.7525\n",
      "Epoch 40/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5198 - accuracy: 0.7531\n",
      "Epoch 41/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5198 - accuracy: 0.7537\n",
      "Epoch 42/100\n",
      "19569/19569 [==============================] - 2s 81us/sample - loss: 0.5194 - accuracy: 0.7536\n",
      "Epoch 43/100\n",
      "19569/19569 [==============================] - 2s 80us/sample - loss: 0.5193 - accuracy: 0.7533\n",
      "Epoch 44/100\n",
      "19569/19569 [==============================] - 2s 80us/sample - loss: 0.5198 - accuracy: 0.7533\n",
      "Epoch 45/100\n",
      "19569/19569 [==============================] - 2s 90us/sample - loss: 0.5195 - accuracy: 0.7533\n",
      "Epoch 46/100\n",
      "19569/19569 [==============================] - 2s 86us/sample - loss: 0.5193 - accuracy: 0.7531\n",
      "Epoch 47/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5192 - accuracy: 0.7527\n",
      "Epoch 48/100\n",
      "19569/19569 [==============================] - 2s 107us/sample - loss: 0.5189 - accuracy: 0.7531\n",
      "Epoch 49/100\n",
      "19569/19569 [==============================] - 2s 93us/sample - loss: 0.5192 - accuracy: 0.7530\n",
      "Epoch 50/100\n",
      "19569/19569 [==============================] - 2s 102us/sample - loss: 0.5189 - accuracy: 0.7529\n",
      "Epoch 51/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5184 - accuracy: 0.7534\n",
      "Epoch 52/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5183 - accuracy: 0.7531\n",
      "Epoch 53/100\n",
      "19569/19569 [==============================] - 2s 82us/sample - loss: 0.5187 - accuracy: 0.7536\n",
      "Epoch 54/100\n",
      "19569/19569 [==============================] - 2s 80us/sample - loss: 0.5189 - accuracy: 0.7531\n",
      "Epoch 55/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5184 - accuracy: 0.7539\n",
      "Epoch 56/100\n",
      "19569/19569 [==============================] - 2s 89us/sample - loss: 0.5185 - accuracy: 0.7534\n",
      "Epoch 57/100\n",
      "19569/19569 [==============================] - 2s 91us/sample - loss: 0.5186 - accuracy: 0.7537\n",
      "Epoch 58/100\n",
      "19569/19569 [==============================] - 2s 96us/sample - loss: 0.5180 - accuracy: 0.7540\n",
      "Epoch 59/100\n",
      "19569/19569 [==============================] - 2s 81us/sample - loss: 0.5183 - accuracy: 0.7532\n",
      "Epoch 60/100\n",
      "19569/19569 [==============================] - 2s 88us/sample - loss: 0.5181 - accuracy: 0.7536\n",
      "Epoch 61/100\n",
      "19569/19569 [==============================] - 2s 85us/sample - loss: 0.5184 - accuracy: 0.7537\n",
      "Epoch 62/100\n",
      "19569/19569 [==============================] - 2s 83us/sample - loss: 0.5184 - accuracy: 0.7543\n",
      "Epoch 63/100\n",
      "19569/19569 [==============================] - 3s 132us/sample - loss: 0.5181 - accuracy: 0.7538\n",
      "Epoch 64/100\n",
      "19569/19569 [==============================] - 3s 156us/sample - loss: 0.5179 - accuracy: 0.7532\n",
      "Epoch 65/100\n",
      "19569/19569 [==============================] - 3s 144us/sample - loss: 0.5180 - accuracy: 0.7536\n",
      "Epoch 66/100\n",
      "19569/19569 [==============================] - 3s 160us/sample - loss: 0.5176 - accuracy: 0.7537\n",
      "Epoch 67/100\n",
      "19569/19569 [==============================] - 3s 156us/sample - loss: 0.5174 - accuracy: 0.7542\n",
      "Epoch 68/100\n",
      "19569/19569 [==============================] - 4s 191us/sample - loss: 0.5177 - accuracy: 0.7542\n",
      "Epoch 69/100\n",
      "19569/19569 [==============================] - 4s 182us/sample - loss: 0.5176 - accuracy: 0.7538\n",
      "Epoch 70/100\n",
      "19569/19569 [==============================] - 3s 143us/sample - loss: 0.5173 - accuracy: 0.7538\n",
      "Epoch 71/100\n",
      "19569/19569 [==============================] - 2s 100us/sample - loss: 0.5172 - accuracy: 0.7542\n",
      "Epoch 72/100\n",
      "19569/19569 [==============================] - 3s 163us/sample - loss: 0.5174 - accuracy: 0.7537\n",
      "Epoch 73/100\n",
      "19569/19569 [==============================] - 4s 180us/sample - loss: 0.5170 - accuracy: 0.7542\n",
      "Epoch 74/100\n",
      "19569/19569 [==============================] - 3s 149us/sample - loss: 0.5175 - accuracy: 0.7543\n",
      "Epoch 75/100\n",
      "19569/19569 [==============================] - 3s 144us/sample - loss: 0.5170 - accuracy: 0.7540\n",
      "Epoch 76/100\n",
      "19569/19569 [==============================] - 3s 154us/sample - loss: 0.5173 - accuracy: 0.7537\n",
      "Epoch 77/100\n",
      "19569/19569 [==============================] - 3s 138us/sample - loss: 0.5172 - accuracy: 0.7540\n",
      "Epoch 78/100\n",
      "19569/19569 [==============================] - 3s 131us/sample - loss: 0.5172 - accuracy: 0.7536\n",
      "Epoch 79/100\n",
      "19569/19569 [==============================] - 3s 147us/sample - loss: 0.5173 - accuracy: 0.7549\n",
      "Epoch 80/100\n",
      "19569/19569 [==============================] - 3s 168us/sample - loss: 0.5170 - accuracy: 0.7540\n",
      "Epoch 81/100\n",
      "19569/19569 [==============================] - 3s 142us/sample - loss: 0.5174 - accuracy: 0.7540\n",
      "Epoch 82/100\n",
      "19569/19569 [==============================] - 3s 145us/sample - loss: 0.5168 - accuracy: 0.7540\n",
      "Epoch 83/100\n",
      "19569/19569 [==============================] - 3s 137us/sample - loss: 0.5170 - accuracy: 0.7546\n",
      "Epoch 84/100\n",
      "19569/19569 [==============================] - 3s 149us/sample - loss: 0.5171 - accuracy: 0.7538\n",
      "Epoch 85/100\n",
      "19569/19569 [==============================] - 3s 158us/sample - loss: 0.5171 - accuracy: 0.7538\n",
      "Epoch 86/100\n",
      "19569/19569 [==============================] - 3s 153us/sample - loss: 0.5168 - accuracy: 0.7536\n",
      "Epoch 87/100\n",
      "19569/19569 [==============================] - 3s 146us/sample - loss: 0.5165 - accuracy: 0.7539\n",
      "Epoch 88/100\n",
      "19569/19569 [==============================] - 3s 140us/sample - loss: 0.5169 - accuracy: 0.7540\n",
      "Epoch 89/100\n",
      "19569/19569 [==============================] - 3s 167us/sample - loss: 0.5167 - accuracy: 0.7538\n",
      "Epoch 90/100\n",
      "19569/19569 [==============================] - 3s 160us/sample - loss: 0.5167 - accuracy: 0.7543\n",
      "Epoch 91/100\n",
      "19569/19569 [==============================] - 3s 168us/sample - loss: 0.5165 - accuracy: 0.7536\n",
      "Epoch 92/100\n",
      "19569/19569 [==============================] - 3s 170us/sample - loss: 0.5166 - accuracy: 0.7542\n",
      "Epoch 93/100\n",
      "19569/19569 [==============================] - 3s 167us/sample - loss: 0.5164 - accuracy: 0.7534\n",
      "Epoch 94/100\n",
      "19569/19569 [==============================] - 3s 168us/sample - loss: 0.5164 - accuracy: 0.7536\n",
      "Epoch 95/100\n",
      "19569/19569 [==============================] - 3s 153us/sample - loss: 0.5162 - accuracy: 0.7554\n",
      "Epoch 96/100\n",
      "19569/19569 [==============================] - 3s 148us/sample - loss: 0.5164 - accuracy: 0.7545\n",
      "Epoch 97/100\n",
      "19569/19569 [==============================] - 3s 159us/sample - loss: 0.5164 - accuracy: 0.7541\n",
      "Epoch 98/100\n",
      "19569/19569 [==============================] - 3s 147us/sample - loss: 0.5164 - accuracy: 0.7547\n",
      "Epoch 99/100\n",
      "19569/19569 [==============================] - 3s 156us/sample - loss: 0.5162 - accuracy: 0.7547\n",
      "Epoch 100/100\n",
      "19569/19569 [==============================] - 3s 159us/sample - loss: 0.5162 - accuracy: 0.7537\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled2, y_train2, epochs=100, callbacks=[model_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6524/1 - 1s - loss: 0.5515 - accuracy: 0.7503\n",
      "Loss: 0.5393643098912453, Accuracy: 0.7503065466880798\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled2,y_test2,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('AlphabetSoupCharity_Optimization.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "In this project, a binary classifier neural network is developed. The neural network that is intended to predict whether or not organizations that apply for funding from Alphabet Soup will be successful. \n",
    "\n",
    "The Neural network is trained on a CSV containing over 34,000 organizations funded byAlphabet Soup over the years.\n",
    "\n",
    "5 different neural network were compiled and trained. throughput the project, steps taken to optimize the neural network's performance and attempt at imporving the accuracy score, in both the data processing and training stages. \n",
    "\n",
    "\n",
    "# Results:\n",
    "\n",
    "#### Data Preprocessing\n",
    "\n",
    "* Target variable: \n",
    "    * IS_SUCCESSFUL — Was the money used effectively  \n",
    "    \n",
    "* Features:\n",
    "    * In the first 4 attempts:\n",
    "        * **APPLICATION_TYPE**—Alphabet Soup application type\n",
    "        * **AFFILIATION**—Affiliated sector of industry\n",
    "        * **CLASSIFICATION**—Government organization classification\n",
    "        * **USE_CASE**—Use case for funding\n",
    "        * **ORGANIZATION**—Organization type\n",
    "        * **STATUS**—Active status\n",
    "        * **INCOME_AMT**—Income classification\n",
    "        * **SPECIAL_CONSIDERATIONS**—Special consideration for application\n",
    "        * **ASK_AMT**—Funding amount requested\n",
    "\n",
    "    * In the 5th attempt, SPECIAL_CONSIDERATIONS (Special consideration for application) was removed.\n",
    "\n",
    "* Variables removed from the input data\n",
    "    * **EIN** and **NAME**—Identification columns\n",
    "\n",
    "        \n",
    "Compiling, Training, and Evaluating the Model\n",
    "How many neurons, layers, and activation functions did you select for your neural network model, and why?\n",
    "Were you able to achieve the target model performance?\n",
    "What steps did you take to try and increase model performance?\n",
    "Summary: Summarize the overall results of the deep learning model. Include a recommendation for how a different model could solve this classification problem, and explain your recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
